{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "#import library or packages\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "import cv2\n",
        "from nets.resnet import resnet34\n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "import os\n",
        "import torchvision.utils as vutils\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import random\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of training samples: 0\n",
            "Number of validation samples: 0\n",
            "\n",
            "Random sample training data:\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Sample larger than population or is negative",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Randomly print 5 images from the training dataset\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mRandom sample training data:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 30\u001b[0m print_random_samples(train_dataset, num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Randomly print 5 images from the validation dataset\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mRandom sample validation data:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "Cell \u001b[0;32mIn[2], line 19\u001b[0m, in \u001b[0;36mprint_random_samples\u001b[0;34m(dataset, num_samples)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprint_random_samples\u001b[39m(dataset, num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# Randomly select indices from the dataset\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m     random_indices \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(dataset)), num_samples)\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m# Print the details of the randomly selected images\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(random_indices):\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.11/random.py:456\u001b[0m, in \u001b[0;36mRandom.sample\u001b[0;34m(self, population, k, counts)\u001b[0m\n\u001b[1;32m    454\u001b[0m randbelow \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_randbelow\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m k \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m n:\n\u001b[0;32m--> 456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSample larger than population or is negative\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    457\u001b[0m result \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m k\n\u001b[1;32m    458\u001b[0m setsize \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m21\u001b[39m        \u001b[38;5;66;03m# size of a small set minus size of an empty list\u001b[39;00m\n",
            "\u001b[0;31mValueError\u001b[0m: Sample larger than population or is negative"
          ]
        }
      ],
      "source": [
        "# data load, transdorm and pre plot\n",
        "from datamodule.dataloader import RotatedReceiptDataset, get_data_transforms\n",
        "from plotmodule.plot_utils import plot_samples_from_each_class \n",
        "\n",
        "# Now you can call the function with any image size\n",
        "data_transforms = get_data_transforms(image_size=224)\n",
        "\n",
        "#load the data and Assuming data_transforms is already defined\n",
        "train_dataset = RotatedReceiptDataset(root_dir='./data/Receipt_data/train/raw', transform=data_transforms['train'])\n",
        "test_dataset = RotatedReceiptDataset(root_dir='./data/Receipt_data/val/raw', transform=data_transforms['val'])\n",
        "\n",
        "# Print the length (number of samples) in the dataset\n",
        "print(f\"Number of training samples: {len(train_dataset)}\")\n",
        "print(f\"Number of validation samples: {len(test_dataset)}\")\n",
        "\n",
        "# Function to print the shape and label of randomly selected images\n",
        "def print_random_samples(dataset, num_samples=5):\n",
        "    # Randomly select indices from the dataset\n",
        "    random_indices = random.sample(range(len(dataset)), num_samples)\n",
        "\n",
        "    # Print the details of the randomly selected images\n",
        "    for i, idx in enumerate(random_indices):\n",
        "        image, label = dataset[idx]\n",
        "        print(f\"Sample {i + 1}:\")\n",
        "        print(f\" - Image shape: {image.shape}\")  # Tensor shape: (Channels, Height, Width)\n",
        "        print(f\" - Label: {label}\")\n",
        "\n",
        "# Randomly print 5 images from the training dataset\n",
        "print(\"\\nRandom sample training data:\")\n",
        "print_random_samples(train_dataset, num_samples=5)\n",
        "\n",
        "# Randomly print 5 images from the validation dataset\n",
        "print(\"\\nRandom sample validation data:\")\n",
        "print_random_samples(test_dataset, num_samples=5)   \n",
        "\n",
        "# Call the function to plot 5 random images from each of the 4 classes in the training dataset\n",
        "plot_samples_from_each_class(train_dataset, num_samples=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Start train\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/10: 100%|██████████| 23/23 [00:30<00:00,  1.33s/it, lr=0.001, total_loss=0.83] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Start test\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/10: 100%|██████████| 26/26 [00:08<00:00,  3.23it/s, test AP=50]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Start train\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/10: 100%|██████████| 23/23 [00:39<00:00,  1.70s/it, lr=0.00092, total_loss=0.272]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Start test\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/10: 100%|██████████| 26/26 [00:08<00:00,  3.19it/s, test AP=94.2]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Start train\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/10: 100%|██████████| 23/23 [00:29<00:00,  1.28s/it, lr=0.000846, total_loss=0.0833]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Start test\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/10: 100%|██████████| 26/26 [00:08<00:00,  2.93it/s, test AP=97.1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Start train\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/10: 100%|██████████| 23/23 [00:43<00:00,  1.90s/it, lr=0.000779, total_loss=0.0734]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Start test\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/10: 100%|██████████| 26/26 [00:12<00:00,  2.11it/s, test AP=98.1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Start train\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/10: 100%|██████████| 23/23 [00:40<00:00,  1.74s/it, lr=0.000716, total_loss=0.122]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Start test\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/10: 100%|██████████| 26/26 [00:09<00:00,  2.66it/s, test AP=98.1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Start train\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/10: 100%|██████████| 23/23 [00:33<00:00,  1.48s/it, lr=0.000659, total_loss=0.0138]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Start test\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/10: 100%|██████████| 26/26 [00:08<00:00,  2.98it/s, test AP=98.1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Start train\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/10: 100%|██████████| 23/23 [00:33<00:00,  1.45s/it, lr=0.000606, total_loss=0.0173] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Start test\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/10: 100%|██████████| 26/26 [00:07<00:00,  3.33it/s, test AP=99]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Start train\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/10: 100%|██████████| 23/23 [00:30<00:00,  1.33s/it, lr=0.000558, total_loss=0.0144]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Start test\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/10: 100%|██████████| 26/26 [00:07<00:00,  3.31it/s, test AP=99]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Start train\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/10: 100%|██████████| 23/23 [00:35<00:00,  1.54s/it, lr=0.000513, total_loss=0.00676]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Start test\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/10: 100%|██████████| 26/26 [00:08<00:00,  3.21it/s, test AP=99]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Start train\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/10: 100%|██████████| 23/23 [00:35<00:00,  1.55s/it, lr=0.000472, total_loss=0.00727]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Start test\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/10: 100%|██████████| 26/26 [00:11<00:00,  2.32it/s, test AP=99]  \n"
          ]
        }
      ],
      "source": [
        "from debug_images.debug_utils import save_first_batch_images  # Import the debugging function\n",
        "\n",
        "# --------------------------------------------------------------------\n",
        "# Utility Functions\n",
        "# --------------------------------------------------------------------\n",
        "\n",
        "# Function to get the current learning rate \n",
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']\n",
        "\n",
        "# --------------------------------------------------------------------\n",
        "# Training and Validation Loop (Main Function)\n",
        "# --------------------------------------------------------------------\n",
        "\n",
        "def fit_one_epoch(net, softmaxloss, epoch, epoch_size, epoch_size_val, gen, gen_test, Epoch, cuda, save_first_batch_images_flag=False):\n",
        "    \"\"\"\n",
        "    Trains and validates the model for one epoch.\n",
        "    \n",
        "    Args:\n",
        "        net: Neural network model.\n",
        "        softmaxloss: Loss function, typically CrossEntropyLoss.\n",
        "        epoch: Current epoch number.\n",
        "        epoch_size: Number of batches in training dataset.\n",
        "        epoch_size_val: Number of batches in validation dataset.\n",
        "        gen: Training data DataLoader.\n",
        "        gen_test: Validation data DataLoader.\n",
        "        Epoch: Total number of epochs.\n",
        "        cuda: Whether to use GPU for training.\n",
        "        save_first_batch_images_flag: Flag to save images from the first batch for debugging.\n",
        "    \"\"\"\n",
        "    # ----------------------------------------------------------------\n",
        "    # Training Phase\n",
        "    # ----------------------------------------------------------------\n",
        "    print('\\nStart train')\n",
        "    net.train()  # Set the model to training mode\n",
        "    total_loss = 0\n",
        "\n",
        "    with tqdm(total=epoch_size, desc=f'Epoch {epoch + 1}/{Epoch}', postfix=dict, mininterval=0.3) as pbar:\n",
        "        for iteration, batch in enumerate(gen):\n",
        "            images, targets = batch[0], batch[1]\n",
        "\n",
        "            # Move data to GPU if available\n",
        "            if cuda:\n",
        "                images = images.cuda()\n",
        "                targets = targets.cuda()\n",
        "\n",
        "            # Optionally save the first batch images for debugging\n",
        "            if save_first_batch_images_flag:\n",
        "                save_first_batch_images(epoch, iteration, images, targets)\n",
        "\n",
        "            # Zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass outputs,_ = net(images)\n",
        "            outputs= net(images)\n",
        "\n",
        "            # Handle tuple outputs (if model returns multiple outputs)\n",
        "            if isinstance(outputs, tuple):\n",
        "                outputs = outputs[0]\n",
        "\n",
        "            # Compute loss\n",
        "            loss = softmaxloss(outputs, targets)\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update total loss\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Update progress bar with current total loss and learning rate\n",
        "            pbar.set_postfix(**{\n",
        "                'total_loss': float(total_loss / (iteration + 1)),\n",
        "                'lr': get_lr(optimizer)\n",
        "            })\n",
        "            pbar.update(1)\n",
        "\n",
        "    # ----------------------------------------------------------------\n",
        "    # Validation Phase\n",
        "    # ----------------------------------------------------------------\n",
        "    print('\\nStart test')\n",
        "    net.eval()  # Set the model to evaluation mode\n",
        "    test_correct = 0  # Variable to track number of correct predictions\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient computation for validation\n",
        "        with tqdm(total=epoch_size_val, desc=f'Epoch {epoch + 1}/{Epoch}', postfix=dict, mininterval=0.3) as pbar:\n",
        "            for iteration, batch in enumerate(gen_test):\n",
        "                images, targets = batch[0], batch[1]\n",
        "\n",
        "                # Move data to GPU if available\n",
        "                if cuda:\n",
        "                    images = images.cuda()\n",
        "                    targets = targets.cuda()\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = net(images)\n",
        "\n",
        "                # Handle tuple outputs (if model returns multiple outputs)\n",
        "                if isinstance(outputs, tuple):\n",
        "                    outputs = outputs[0]\n",
        "\n",
        "                # Get the predicted class (highest score)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "                # Count number of correct predictions\n",
        "                test_correct += torch.sum(predicted == targets).item()\n",
        "\n",
        "                # Update progress bar with test accuracy\n",
        "                pbar.set_postfix(**{\n",
        "                    'test AP': float(100 * test_correct / len(gen_test.dataset))\n",
        "                })\n",
        "                pbar.update(1)\n",
        "\n",
        "    # ----------------------------------------------------------------\n",
        "    # Save Model After Epoch\n",
        "    # ----------------------------------------------------------------\n",
        "    torch.save(net.state_dict(), f'logs/Epoch{epoch + 1}-Total_Loss{round(total_loss / epoch_size, 4)}.pth')\n",
        "\n",
        "\n",
        "# Main script to run training and validation\n",
        "if __name__ == '__main__':\n",
        "    # ----------------------------------------------------------------\n",
        "    # System Setup\n",
        "    # ----------------------------------------------------------------\n",
        "    # Automatically detect if CUDA (GPU) is available\n",
        "    cuda = torch.cuda.is_available()\n",
        "\n",
        "    # Define training configuration variables\n",
        "    pre_train = False      # Whether to load a pretrained model\n",
        "    CosineLR = False       # Whether to use Cosine Annealing LR scheduler\n",
        "    lr = 1e-3              # Learning rate\n",
        "    Batch_size = 8         # Batch size for training\n",
        "    Init_Epoch = 0         # Initial epoch (usually 0)\n",
        "    Fin_Epoch = 10         # Final epoch (number of epochs to train)\n",
        "\n",
        "    # ----------------------------------------------------------------\n",
        "    # Model Creation\n",
        "    # ----------------------------------------------------------------\n",
        "    # Create the model (example using ResNet34)\n",
        "    model = resnet34(num_classes=4)  # Assuming 4 classes\n",
        "\n",
        "    # Load the pretrained model if needed\n",
        "    if pre_train:\n",
        "        model_path = 'logs/resnet50-mnist.pth'  # Path to the pre-trained model\n",
        "        if cuda:\n",
        "            model.load_state_dict(torch.load(model_path))\n",
        "        else:\n",
        "            model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
        "\n",
        "    # Set the device (either GPU or CPU)\n",
        "    device = torch.device('cuda' if cuda else 'cpu')\n",
        "    model = model.to(device)\n",
        "\n",
        "    # ----------------------------------------------------------------\n",
        "    # Data Loading\n",
        "    # ----------------------------------------------------------------\n",
        "    # Assuming `train_dataset` and `test_dataset` are already defined elsewhere\n",
        "    gen = DataLoader(dataset=train_dataset, batch_size=Batch_size, shuffle=True, num_workers=0)\n",
        "    gen_test = DataLoader(dataset=test_dataset, batch_size=Batch_size // 2, shuffle=True, num_workers=0)\n",
        "\n",
        "    epoch_size = len(gen)         # Number of training batches per epoch\n",
        "    epoch_size_val = len(gen_test)  # Number of validation batches per epoch\n",
        "\n",
        "    # ----------------------------------------------------------------\n",
        "    # Loss Function and Optimizer\n",
        "    # ----------------------------------------------------------------\n",
        "    # Define the loss function (CrossEntropyLoss for classification)\n",
        "    softmax_loss = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    # Define the optimizer (Adam optimizer in this case)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    # ----------------------------------------------------------------\n",
        "    # Learning Rate Scheduler\n",
        "    # ----------------------------------------------------------------\n",
        "    # Choose the learning rate scheduler\n",
        "    if CosineLR:\n",
        "        lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=5, eta_min=1e-10)\n",
        "    else:\n",
        "        lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.92)\n",
        "\n",
        "    # ----------------------------------------------------------------\n",
        "    # Training Loop\n",
        "    # ----------------------------------------------------------------\n",
        "    # Loop over the range of epochs\n",
        "    for epoch in range(Init_Epoch, Fin_Epoch):\n",
        "        # Train and validate for one epoch\n",
        "        fit_one_epoch(net=model, \n",
        "                      softmaxloss=softmax_loss, \n",
        "                      epoch=epoch, \n",
        "                      epoch_size=epoch_size,\n",
        "                      epoch_size_val=epoch_size_val, \n",
        "                      gen=gen, \n",
        "                      gen_test=gen_test, \n",
        "                      Epoch=Fin_Epoch, \n",
        "                      cuda=cuda)\n",
        "        \n",
        "        # Step the learning rate scheduler\n",
        "        lr_scheduler.step()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
